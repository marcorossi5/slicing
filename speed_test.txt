All the experiments have been done with K=32 and min_hits=300 to fit the minimum
size GPU. The only exception is given by the "full" test, which means K=256 and
min_hits=1, deployed on the A100 gpu.

------------------------------------------------------------------------------------------------------------------------------------------------------------------
| Device | CPU model               | CPU cores        | CPU RAM          | GPUS(s) model          | GPU memory       | Relase date | FP64         | FP32         |
------------------------------------------------------------------------------------------------------------------------------------------------------------------
| D0     | i7-10510U               | 4 @ 1.8-4.9 GHz  | 16 GB @ 2133 MHz |           -            |         -        |      -      |      -       |      -       |
------------------------------------------------------------------------------------------------------------------------------------------------------------------
| D1     | i9-9980XE               | 18 @ 3-4.4 GHz   | 30 GB @ 2666 Mhz | Nvidia TITAN V         | 12 GB @ 653 GB/s | Dec 2017    | 7.45 TFLOPS  | 14.90 TFLOPS |
|        |                         |                  |                  | Nvidia RTX 2080 Ti     | 11 GB @ 616 GB/s | Sep 2018    | 0.42 TFLOPS  | 13.54 TFLOPS |
------------------------------------------------------------------------------------------------------------------------------------------------------------------
| D2     | Xeon Scalable Processor | 12 @ 2.2-3.7 GHz | 30 GB            | Nvidia A100-SXM4       | 40 GB @ 1.6 TB/s | May 2020    | 9.7 TFLOPS   | 19.5 TFLOPS  |
------------------------------------------------------------------------------------------------------------------------------------------------------------------
| D3     | Xeon E7                 | 8 @ 2.0-3.5 GHz  | 30 GB            | Nvidia Tesla T4        | 16 GB @ 320 GB/s | Sep 2018    | 0.25 TFLOPS* | 8.1 TFLOPS   |
|        |                         |                  |                  | Nvidia Tesla V100 SXM2 | 16 GB @ 900 GB/s | Jun 2017    | 7.8 TFLOPS   | 15.7 TFLOPS  |
|        |                         |                  |                  | Nvidia Tesla P4        | 8 GB @ 192 GB/s  | Sep 2016    | 0.2 TFLOPS*  | 5.5 TFLOPS   |
|        |                         |                  |                  | Nvidia Tesla P100 PCIe | 16 GB @ 732 GB/s | Jun 2016    | 4.7 TFLOPS   | 9.3 TFLOPS   |
------------------------------------------------------------------------------------------------------------------------------------------------------------------
| D4     | Xeon E5                 | 8 @ 2.2-3.7 GHz  | 30 GB            | Nvidia Tesla K80       | 12 GB @ 240 GB/s | Nov 2014    | 1.46 TFLOPS  | 4.37 TFLOPS  |
------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
    - CPU cores: <physical cores> @ <base frequency>-<single core max turbo frequency>
    - GPU memory: <memory> @ <total memory bandwidth>
    * To allow FP64 code to work correctly, a small number of FP64 hardware
      units are included in the T4 and P4 GPU architecture.

CPU notes:
    - D0 Comet Lake
    - D2 is A2 accelerator-optimized cpu, Intel Cascade Lake
    - D3 is N1 general-purpose cpu, Intel Skylake
    - D4 is N1 general-purpose cpu, Intel Broadwell

GPU notes:
    - A100 interconnected with NVLink Full Mesh @ 600 GB/s
    - V100 interconnected with NVLink Ring @ 300 GB/s

Accelerator-optimized are ideal for massively parallelized CUDA compute
workloads, such as machine learning (ML) and high performance computing (HPC).

General-purpose machine types offer the best price-performance ratio for a
variety of workloads.

For more information on google cloud machines see: https://cloud.google.com/compute/docs/machine-types

----------------------------------------------------------------------------------------------------------------------------------------------------------------
| Device           | Wall time | Input time | Kernel Launch time | CPU compute time | GPU compute Time | CPU Ops | GPU Ops | Others time | Fragmentation (mean)|
----------------------------------------------------------------------------------------------------------------------------------------------------------------
| D0 (cpu)         | 1272.8 ms | 6.1 ms     |         -          | 1266.4 ms        |        -         | 100 %   |    -    | 0.4 ms      |          -          |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
| D1 (cpu)         | 1466.6 ms | 13.7 ms    |         -          | 1452.5 ms        |        -         | 100 %   |    -    | 0.4 ms      |          -          |
| D1 (TITAN V)     | 294.1 ms  | 53.3 ms    | 45.6 ms            | 2.2 ms           | 148.0 ms         | 1.3 %   | 98.7 %  | 44.9 ms     | 12.22 % (6.46 %)    |
| D1 (RTX 2080 Ti) | 294.9 ms  | 34.8 ms    | 35.0 ms            | 2.1 ms           | 211.5 ms         | 1.3 %   | 98.7 %  | 11.4 ms     | 13.42 % (3.40 %)    |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
| D2 (cpu)         | 344.1 ms  | 6.9 ms     |         -          | 336.8 ms         |        -         | 100 %   |    -    | 0.5 ms      |          -          |
| D2 (A100)        | 95.0 ms   | 6.0 ms     | 38.8 ms            | 0.2 ms           | 47.2 ms          | 1.3 %   | 98.7 %  | 2.8 ms      | 31.30 % (27.41 %)   |
| D2 (A100, full)  | 201.7 ms  | 19.5 ms    | 17.0 ms            | 0.2 ms           | 157.0 ms         | 1.3 %   | 98.7 %  | 7.9 ms      | 49.50 % (1.54 %)    |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
| D3 (cpu)         | 709.6 ms  | 7.3 ms     |         -          | 701.8 ms         |        -         | 100 %   |    -    | 0.5 ms      |          -          |
| D3 (T4)          | 121.4 ms  | 5.6 ms     | 18.8 ms            | 0.2 ms           | 91.8 ms          | 1.2 %   | 98.8 %  | 5.0 ms      | 48.86 % (46.75 %)   |
| D3 (V100)        | 91.5 ms   | 5.6 ms     | 42.1 ms            | 0.4 ms           | 40.3 ms          | 1.3 %   | 98.7 %  | 3.0 ms      | 48.86 % (46.74 %)   |
| D3 (P4)          | 121.1 ms  | 5.9 ms     | 17.3 ms            | 0.2 ms           | 98.5 ms          | 1.3 %   | 98.7 %  | 4.1 ms      | 6.67 % (0.12 %)     |
| D3 (P100)        | 92.8 ms   | 5.6 ms     | 28.9 ms            | 0.2 ms           | 55.2 ms          | 1.3 %   | 98.7 %  | 2.9 ms      | 48.66 % (46.51 %)   |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
| D4 (cpu)         | 803.8 ms  | 9.0 ms     |         -          | 794.1 ms         |        -         | 100 %   |    -    | 0.7 ms      |          -          |
| D4 (K80)         | 173.8 ms  | 7.3 ms     | 26.7 ms            | 0.2 ms           | 131.4 ms         | 1.3 %   | 98.7 %  | 8.2 ms      | 48.66 % (46.51 %)   |
----------------------------------------------------------------------------------------------------------------------------------------------------------------

Note:
    - Fragmentation is the percentage of physical GPU memory actually spent in
      allocating objects. It can happen that the physical memory used is less
      than this amount, but still we are not free to allocate big chunks of
      memory that exceeds the non-fragmented part.
    - Kernel launch time is the time that the CPU spends on launching the GPU
      compute kernels on the device.
    - Device compute precision is always 100% 32-bit (no 16-bit)
